name: semestr_job

services:
  mongo:
    image: mongo
    env_file:
      - .env
    ports:
      - ${MONGODB_PORT}:${MONGODB_PORT}
    volumes:
      - /data/mongo

  mongo-express:
    image: mongo-express
    env_file:
      - .env
    depends_on:
      - mongo
    ports:
      - ${MONGOEXPRESS_PORT}:${MONGOEXPRESS_PORT}

  spark:
    image: docker.io/bitnami/spark:3.5
    environment:
      - SPARK_MODE=master
    ports:
      - "4040:4040"
      - "8080:8080"
    depends_on:
      - mongo

  spark-worker:
    image: docker.io/bitnami/spark:3.5
    environment:
      - SPARK_MODE=worker
    env_file:
      - .env
    depends_on:
      - spark

  minio:
    image: minio/minio:latest
    container_name: minio
    env_file:
      - .env
    ports:
      - ${MINIO_API_PORT}:9000 # MinIO API
      - ${MINIO_WEB_UI_PORT}:9001 # MinIO Web UI
    volumes:
      - minio_data:/data/s3
    command: server /data/s3 --console-address ":9001"

  postgres:
    container_name: postgres
    image: postgres:17
    env_file:
      - .env
    ports:
      - "${POSTGRES_PORT}:5432"
    volumes:
      - .\postgres_data:/var/lib/postgresql/data

  airflow-webserver:
    container_name: airflow-webserver
    image: apache/airflow:2.1.2
    restart: always
    entrypoint: airflow webserver
    env_file:
      - .env
    ports:
      - "8083:${AIRFLOW_PORT}"
    volumes:
      - .\dags:/opt/airflow/dags
    depends_on:
      - postgres
      - airflow-scheduler

  airflow-scheduler:
    container_name: airflow-scheduler
    image: apache/airflow:2.1.2
    restart: always
    entrypoint: airflow scheduler
    env_file:
      - .env
    volumes:
      - .\dags:/opt/airflow/dags
    depends_on:
      - postgres

  airflow-init:
    container_name: airflow-init
    image: apache/airflow:2.1.2
    entrypoint: /bin/bash -c "airflow db init && airflow users create ${AIRFLOW_USER}"
    env_file:
      - .env
    volumes:
      - .\dags:/opt/airflow/dags
    depends_on:
      - postgres
volumes:
  mongo_data:
  minio_data:
